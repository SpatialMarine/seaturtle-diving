#functions for 02_process_ttdrData.R and 03_diveMetrics. Jessica Harvey-Carroll (carrolljessh@gmail.com/ jessica.carroll@bioenv.gu.se). 2023#
#functions for 02_process_ttdrData.R and 03_diveMetrics. Jessica Harvey-Carroll (carrolljessh@gmail.com/ jessica.carroll@bioenv.gu.se). 2023#
################################################################################
#------------------------------------------------------------------------------#
# Step 0. Preliminaries- load packages #
#------------------------------------------------------------------------------#
################################################################################
require(dplyr)
require(lubridate)
require(diveMove)
library(zoo)
library(changepoint)
library(akima)
library(data.table)
library(beepr)
library(pracma)
library(changepoint)
library(tidyr)

#run functions
#-------------------------------------------------------------------------------
# wc2ttdr  Processes Wildlife Computers Time-Series csv files
#-------------------------------------------------------------------------------
wc2ttdr <- function(data, locale = "English", date_deploy=NULL, tfreq = "5 min"){
  
  
  # Convert to POSIXct
  data$date <- paste(data$Day, data$Time)
  data$date <- parse_date_time(data$date, "dmY HMS", tz="UTC")
  
  # Select data collected from the date of deployment
  if (!is.null(date_deploy)) data <- filter(data, date >= date_deploy)
  
  ### Rename columns
  names(data)[names(data)=="Ptt"] <- "id"
  names(data)[names(data)=="Depth"] <- "depth"
  names(data)[names(data)=="DRange"] <- "drange"
  names(data)[names(data)=="Temperature"] <- "temperature"
  names(data)[names(data)=="TRange"] <- "trange"
  
  ## create a time series for the whole period with NAs
  # id <- data$id[1]  # Get animal id
  min.time <- min(data$date)  # min time stamp
  max.time <- max(data$date)  # max time stamp
  ts.seq <- seq(from = min.time, to = max.time, by = tfreq)  # create complete TS at regular period of time
  ts.seq <- data.frame(date = ts.seq)  # convert to data.frame
  data <- merge(ts.seq, data, by="date", all.x = TRUE)  # merge data with complete sequence
  #data$id[is.na(data$id)] <- id
  
  # Reorder column names
  data <- dplyr::select(data, date, depth, drange, temperature, trange)
  return(data)
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
#descent.func # calculate the point turtles pass descent thresholds for each dive. Add in artificial times. If predicted time same as next time then omit
#-------------------------------------------------------------------------------
descent.func<-function(dataframe){
  
  rwz = which(dataframe$thresh.x == "descent")
  desc.thresh.tim = rep(NA, nrow(dataframe))
  desc.thresh.dep = rep(NA, nrow(dataframe))
  
  for(i in 1:length(rwz)){
    t2<- dataframe[rwz[i],1] 
    t1 <- dataframe[rwz[i]-1,1]  
    
    # select TDR data within a dive 
    fdata <- filter(dataframe, date >= t1 & date <= t2)
    d <- fdata$depth_adj.x#depths
    t <- fdata$date #time (in seconds)
    
    xout <- seq(t1,t2,by="10 sec")
    t <- as.numeric(t-t1)
    xout <- as.numeric(xout-t1)
    
    pred <- aspline(t, d, xout=xout)  # prediction
    
    pt <- which(round(pred$y, digits = 2) >= customDive_threshold)# get depths below dive threshold
    
    td1= xout[pt[1]]  # first time where depth is > than threshold
    if (td1 == 300){
      ptmin=pt-1
      td1= xout[ptmin[1]] 
    }else{
      td1=td1
    }
    
    desc.thresh.tim[rwz[i]] = td1
  }
  
  for(j in 1:length(rwz)){
    t2<- dataframe[rwz[j],1] 
    t1 <- dataframe[rwz[j]-1,1]  
    
    # select TDR data within a dive 
    fdata <- filter(dataframe, date >= t1 & date <= t2)
    d <- fdata$depth_adj.x#depths
    t <- fdata$date #time (in seconds)
    
    xout <- seq(t1,t2,by="10 sec")
    t <- as.numeric(t-t1)
    xout <- as.numeric(xout-t1)
    
    pred <- aspline(t, d, xout=xout, n=2)  # prediction
    
    ##
    pred<-as.data.frame(pred)
    
    pred<-filter(pred,round(y, digits = 2) >= customDive_threshold)
    
    td12<-pred[1,2]
    td12<-round(td12, digits=1)
    
    ####
    desc.thresh.dep[rwz[j]] = td12
  }
  
  
  dataframenew = cbind(dataframe,desc.thresh.tim, desc.thresh.dep)
  
  dataframenew$descenttim <- with(dataframenew, lag(date)+ desc.thresh.tim)
  return(dataframenew)
  
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
#ascent.func # calculate the point turtles pass ascent thresholds for each dive. Add in artificial times. If predicted time same as next time then omit
#-------------------------------------------------------------------------------
ascent.func<-function(dataframe){
  
  rwz = which(dataframe$thresh.x == "ascent")
  asc.thresh.tim = rep(NA, nrow(dataframe))
  asc.thresh.dep = rep(NA, nrow(dataframe))
  
  for(i in 1:length(rwz)){
    t2<- dataframe[rwz[i],1] 
    t1 <- dataframe[rwz[i]-1,1]  
    
    # select TDR data within a dive 
    fdata <- filter(dataframe, date >= t1 & date <= t2)
    d <- fdata$depth_adj.x#depths
    t <- fdata$date #time (in seconds)
    
    xout <- seq(t1,t2,by="10 sec")
    t <- as.numeric(t-t1)
    xout <- as.numeric(xout-t1)
    
    pred <- aspline(t, d, xout=xout, n=2)  # prediction
    
    
    pt <- which(round(pred$y, digits = 2) <= customDive_threshold)# get depths below dive threshold
    
    td1= xout[pt[1]]  # first time where depth is > than threshold
    
    if (td1 == 300){
      ptmin=pt-1
      td1= xout[ptmin[1]] 
    }else{
      td1=td1
    }
    
    asc.thresh.tim[rwz[i]] = td1
    
  }
  
 
    for(j in 1:length(rwz)){
      t2<- dataframe[rwz[j],1] 
      t1 <- dataframe[rwz[j]-1,1]  
      
      # select TDR data within a dive 
      fdata <- filter(dataframe, date >= t1 & date <= t2)
      d <- fdata$depth_adj.x#depths
      t <- fdata$date #time (in seconds)
      
      xout <- seq(t1,t2,by="10 sec")
      t <- as.numeric(t-t1)
      xout <- as.numeric(xout-t1)
      
      pred <- aspline(t, d, xout=xout, n=2)  # prediction
      
      ##
      pred<-as.data.frame(pred)
      
      pred<-filter(pred,round(y, digits = 2) <=  customDive_threshold)
      
      td12<-pred[1,2]
      td12<-round(td12, digits=1)
      
      ####
      asc.thresh.dep[rwz[j]] = td12
    }
  dataframenew = cbind(dataframe,asc.thresh.tim, asc.thresh.dep)
  
  dataframenew$ascenttim <- with(dataframenew, lag(date)+ asc.thresh.tim)
  return(dataframenew)
  
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
# newint # function to get start and fin time of each dive
#-------------------------------------------------------------------------------
newint<-function(dataframe){
  ie<-nrow(dataframe)
  a<-dataframe[ie,2]
  b<-dataframe[1,2]
  # d<-dataframe[1,5]
  newdf<- as.data.frame(dataframe[1,5])
  newdf$start<- b
  newdf$fin<- a
  names(newdf)[1] = "diveno"
  return(newdf)
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
#split.dive # function to split dive if peaks detected and possible for turtle to surface based on trajectory
#-------------------------------------------------------------------------------
split.dive<-function(dataframe){

  
  p<-findpeaks(-dataframe$depth, threshold = 1)
  j<-as.data.frame(p[,2])
  t<-nrow(j)
  fill=rep(NA, t)
  
  if (t>0){
    for (a in 1:nrow(j)){
      j2<-p[,2][a]  
      #depths& times of peak, n-1, n+1
      depthnm1<--dataframe[j2-1,3]
      depthpoint<-p[,1][a]
      depthnp1<--dataframe[j2+1,3]
      
      timenm1<-dataframe[j2-1,2]
      timepoint<-dataframe[j2,2]
      timenp1<-dataframe[j2+1,2]
      
      
      #timediff
      t1<-as.numeric(timepoint-timenm1)*60
      t2<-as.numeric(timenp1-timepoint)*60
      
      #depthdiff
      d1<-depthpoint-depthnm1
      d2<-depthpoint-depthnp1
      
      #calculate speed
      #first speed
      s1<-d1/t1
      #second speed
      s2<-d2/t2
      
      #could turtle cross threshold based on speed before/after peak
      distance_poss1<-s1*150
      distance_poss2<-s2*150
      
      distneeded<- -customDive_threshold-depthpoint
      
      if(distance_poss1>=distneeded || distance_poss2>=distneeded ){
        fill[a] = j[a,]
      }
      
    }
  }
  
  
  if (t>0 & sum(!is.na(fill))>0){
    
    for (k in 1:length(dataframe)){  
      rwz = fill[!is.na(fill)]
      de1=rep(NA, nrow(dataframe))
      newdv1<- .POSIXct(character())
      de2=rep(NA, nrow(dataframe))
      newdv2<- .POSIXct(character())
      de3=rep(NA, nrow(dataframe))
      newdv3<- .POSIXct(character())
      
      for (i in 1:length(rwz)){
        t1<- dataframe[rwz[i],2]
        t2 <- t1+150 
        t<-as.numeric(t1-t1)
        t<-c(t,150)
        d<-c(dataframe[rwz[i],3], 0)
        xout <- seq(t1,t2,by="2 sec") #was 5 secs but values 5.9 so changed for + precision. Was originally was 10 secs but changed becasue duplicate confusion
        xout <- as.numeric(xout-t1)
        pred <- aspline(t, d, xout=xout, n=2)  # prediction
        pt <- which(round(pred$y, digits=2) >= 1.00)# KEEP AS 1m (top of triangle)
        
        
        pt<-rev(pt)
        td1= xout[pt[1]] 
        pt1d<-pt[1]
        
        date<-c(t1+td1)
        depth<- pred$y[pt1d]
        
        newdv1[i] = as.POSIXct(date)
        de1[i] = depth 
        
        #ab.thresh#
        pt2<- which(round(pred$y, digits = 2) >= customDive_threshold)
        pt2<-rev(pt2)
        td1.1= xout[pt2[1]] 
        pt2d<-pt2[1]
        date2<-c(t1+td1.1)
        depth2<- pred$y[pt2d]
        newdv2[i] = as.POSIXct(date2)
        de2[i] = depth2
        
        ###########
        ##descent again, make sure it uses rwz[i], NOT J+1
        tda<- date
        tdb <- dataframe[rwz[i]+1,2] 
        ta<-0 #as.numeric(tdb-tda) #   difftime(tdb,tda, unit="secs"))
        ta<-c(ta,150)
        da<-c(dataframe[rwz[i]+1,3], depth)
        xout2 <- seq(tda, tdb,by="2 sec") #was 10 secs but changed becasue duplicate confusion
        xout2 <- as.numeric(xout2-tda)
        pred2 <- aspline(ta, da, xout=xout2, n=2)  # prediction
        pta <- which(round(pred2$y, digits=2) >= customDive_threshold)# get depths below dive threshold
        pta<-rev(pta)
        td1a= xout[pta[1]] 
        pt1da<-pta[1]
        
        date3<-c(tdb-td1a)
        depth3<- pred2$y[pt1da]
        newdv3[i] = as.POSIXct(date3)
        de3[i] = depth3
      }
      
      de1<-de1[!is.na(de1)]
      de2<-de2[!is.na(de2)]
      de3<-de3[!is.na(de3)]
      
      new_df <- data.frame(date1 = as.POSIXct(newdv1, format="%Y-%m-%d %H:%M:%S",tz="UTC"), 
                           date2=as.POSIXct(newdv2, format="%Y-%m-%d %H:%M:%S",tz="UTC"),
                           date3=as.POSIXct(newdv3, format="%Y-%m-%d %H:%M:%S",tz="UTC"))
      
      new_df2 <- data.frame(dep1=de1,
                            dep2=de2,
                            dep3=de3)
      
      new1<-data.frame(date = as.POSIXct(newdv1, format="%Y-%m-%d %H:%M:%S",tz="UTC"), 
                       dep=de1)
      new2<-data.frame(date=as.POSIXct(newdv2, format="%Y-%m-%d %H:%M:%S",tz="UTC"),
                       dep=de2 )
      new3<-data.frame( date=as.POSIXct(newdv3, format="%Y-%m-%d %H:%M:%S",tz="UTC"),
                        dep=de3)
      
      df<-rbind(new1,new2,new3)
      names(df)[names(df) == "dep"] <- "depth"
      
      
      #final DF!
      multdiv2 <- merge(dataframe,df, by=c("date", "depth"), all = TRUE)
      # multdiv2<- multdiv2[complete.cases(multdiv2[ , 1:2]),]
      multdiv2.2<-na.locf(multdiv2, na.rm = FALSE)
      return(multdiv2.2)
    }
  }
  
}

#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
# phases # function to label surface/ dive phases
#-------------------------------------------------------------------------------
phases<-function(dataframe){
  
  #assign phase (dive/surface) for threshold value
  dataframe1<-dataframe %>%
    mutate(phase = case_when(round(depth) >= customDive_threshold ~ 'dive',
                             TRUE ~ 'surface'))
  
  #add phase of dives (surface etc.)
  dataframe2<-dataframe1 %>%
    mutate(thresh = case_when(lag(phase) == "surface" & phase == "dive" ~ 'descent',
                              lag(phase) == "dive" & phase == "surface" ~ 'ascent',
                              lag(phase) == "dive" & phase == "dive" ~ 'dive',
                              lag(phase) == "surface" & phase == "surface" ~ 'surface',
                              TRUE ~ ''))
  ##add dive numbers
  desc<-dataframe2 %>% filter(thresh == "descent")
  desc$diveno <- 1:nrow(desc) 
  
  #merge dataframes to label dives
  dataframe3<-merge(dataframe2, desc, by = 'date', all.x= TRUE)
  
  #remove bogus y columns but keep original dataframe and new dive numbers
  dataframe3.1 <- dataframe3[ -c(5: 7) ]
  
  dataframe3.2<-na.locf(dataframe3.1,na.rm = FALSE)
  dataframe4 <- within(dataframe3.2, diveno[thresh.x == 'surface'] <- NA)
  
  #change names#
  names(dataframe4)[2] <- 'depth'
  names(dataframe4)[3] <- 'phase'
  names(dataframe4)[4] <- 'thresh'
  
  return(dataframe4)
  
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
# depth.diff # function to calculate depth difference (m) from previous depth
#-------------------------------------------------------------------------------
depth.diff<-function(dataframe){
  #depth difference#
  diff = rep(NA,nrow(dataframe))
  for(i in 2:nrow(dataframe)){
    a = dataframe$depth[i]
    b = dataframe$depth[i - 1]
    c = a-b
    diff[i] = c
  }
  dataframe2<-cbind(dataframe,diff)
  return(dataframe2)
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
# time.diff # function to calculate time difference (s) from previous time
#-------------------------------------------------------------------------------
time.diff<-function(dataframe){
  tim = rep(NA,nrow(dataframe))
  for(i in 2:nrow(dataframe)){
    a = dataframe$date[i]
    b = dataframe$date[i - 1]
    c = difftime(a,b, unit="secs")
    tim[i] = c
  }
  dataframe2<-cbind(dataframe,tim)
  return(dataframe2)
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
# speed.diff # function to calculate speed difference (m/s) from previous speed
#-------------------------------------------------------------------------------
speed<-function(dataframe){
  spd = rep(NA,nrow(dataframe))
  for(i in 2:nrow(dataframe)){
    a = abs(dataframe$diff[i])
    b = dataframe$tim[i]
    if (b==0){
      c=0
    }
    else {
      c = a/b
    }
    if (c== "NaN") {
      c=0
    }
    spd[i] = c
    
  }
  dataframe2<-cbind(dataframe,spd)
  return(dataframe2)
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
# dive.phaselab # function to label phases of dive
#-------------------------------------------------------------------------------
dive.phaselab<-function(dataframe){
  
  dataframeDepthError<-dataframe
  
  dataframe<-dataframe %>% select(date,depth,phase,thresh,diveno,diff,tim,spd,direction)
  
  
  #descent
  p<-dataframe$depth[which.max(dataframe$depth)]
  p2<-p*0.8
  t<-which(dataframe$depth >=p2)
  
  if (length(t)== nrow(dataframe)| p2 <= dataframe[1,2]){
    #for 3 point dives or very shallow dives (0.8Xmax depth < first reading)
    p<-which.max(dataframe$depth)
    p=p-1
    dataframe$descent<- NA
    dataframe[1:p,10]<- "descent"
    
    #ascent
    #find max depth and first occurance of max depth
    x<-dataframe$depth[which.max(dataframe$depth)]
    asc<-dataframe %>% filter(depth == x)
    asc$a <- +(!duplicated(asc$depth, fromLast=T))
    df <- asc[ -c(2:10) ]
    dataframe<-merge(dataframe, df, by = 'date', all.x= TRUE)
    
    dataframe<-dataframe %>%
      mutate(ph = case_when(descent == 'descent' ~ 'descent',
                            depth == x ~ 'bottom', 
                            lag(a) == 1 ~ 'ascent',
                            TRUE ~ as.character(NA)))
    
    dataframe$ph<-na.locf(dataframe$ph,na.rm = FALSE)
    
    dataframe<-dataframe %>%
      mutate(ph2 = case_when(ph == 'descent' ~ 'descent',
                             ph == 'ascent' ~ 'ascent', 
                             depth == x ~ 'bottom',
                             TRUE ~ 'n'))
    
    dataframe<-dataframe %>%
      mutate(ph3 = case_when(ph2 == 'n' & direction == 'positive' ~ 'minidesc',
                             ph2 == 'n' & direction == 'negative' ~ 'miniasc',
                             ph2 == 'n' & direction == 'no change' ~ 'hangout',
                             ph2 == 'descent'~ 'descent',
                             ph2 == 'ascent'~ 'ascent',
                             ph2 == 'bottom'~ 'bottom',
                             TRUE ~ as.character(NA)))
    
    
    dataframe <- dataframe[ -c(10:13) ]
    dataframe <- dataframe[ -c(6:8) ]
    
    dataframe<-depth.diff(dataframe)
    dataframe<-time.diff(dataframe)  
    dataframe<-speed(dataframe)
    
    if("depthUpperError" %in% colnames(dataframeDepthError)){
      depthErrorDF<-  dataframeDepthError %>% select(date,depthUpperError, depthLowerError)
      depthErrorDF$date <- as.POSIXct(depthErrorDF$date,format="%Y-%m-%d %H:%M:%S",tz="CET") 
      depthErrorDFMerge<- merge(dataframe, depthErrorDF, by="date", all.x = TRUE) 
      depthErrorDFMerge<-depthErrorDFMerge[order(depthErrorDFMerge$date),]
      dataframe<-depthErrorDFMerge
    }
    
    
    return(dataframe)
  }
  else {
    p3<-which(dataframe$depth >=p2)[1]
    p4=p3-1
    dataframe$descent<- NA
    #dataframe[1:p4,10]<- "descent"
    dataframe$descent[1:p4] <- "descent"
    
    
    #ascent
    #find max depth and first occurance of max depth
    x<-dataframe$depth[which.max(dataframe$depth)]
    asc<-dataframe %>% filter(depth <= (x*0.8) & is.na(descent))
    asc$a <- "ascent"
    df <- asc[ -c(2:10) ]
    dataframe<-merge(dataframe, df, by = 'date', all.x= TRUE)
    
    dataframe<-dataframe %>%
      mutate(ph = case_when(descent == 'descent' ~ 'descent',
                            depth >= p2 ~ 'bottom', 
                            a == 'ascent' ~ 'ascent',
                            TRUE ~ as.character(NA)))
    
    dataframe$ph<-na.locf(dataframe$ph,na.rm = FALSE)
    
    dataframe<-dataframe %>%
      mutate(ph2 = case_when(ph == 'descent' ~ 'descent',
                             ph == 'ascent' ~ 'ascent', 
                             depth >= p2 ~ 'bottom',
                             TRUE ~ 'n'))
    
    
    ##mini peaks##
    bs<-which(dataframe$depth >=p2)[1]
    
    be<-rev(which(dataframe$depth >=p2))[1]
    
    b<-dataframe[bs:be,]
    
    
    dataframe2<-b %>%
      mutate(ph3 = case_when(depth >= p2 ~ 'bottom',
                             ph2=='ascent' & direction == 'positive' ~ 'minidesc',
                             ph2 == 'ascent' & direction == 'negative' ~ 'miniasc',
                             ph2 == 'ascent' & direction == 'no change' ~ 'hangout',
                             TRUE ~ as.character(NA)))
    
    
    dataframe2.1<-dataframe2[,c(1,14)]
    
    
    dataframe3<-merge(dataframe, dataframe2.1, by = 'date', all.x= TRUE)
    
    dataframe4<-dataframe3 %>%
      mutate(ph2.1 = case_when(ph2=='ascent' & is.na(ph3) ~ 'ascent',
                               ph2 == 'descent' &  is.na(ph3) ~ 'descent',
                               ph3 == 'bottom' ~ 'bottom',
                               ph3 == 'miniasc' ~ 'miniasc',
                               ph3 == 'minidesc' ~ 'minidesc',
                               ph3 == 'hangout' ~ 'hangout',
                               TRUE ~ as.character(NA)))
    
    
    
    dataframenew<-dataframe4[c("date","depth","phase","thresh","diveno","direction","ph2.1", "diff", "tim", "spd")]
    names(dataframenew)[names(dataframenew) == "ph2.1"] = "ph3"
    
    dataframenew<-depth.diff(dataframenew)
    dataframenew<-time.diff(dataframenew)  
    dataframenew<-speed(dataframenew)
    
    dataframenew<- dataframenew[-c(8:10)]
    
    
    if("depthUpperError" %in% colnames(dataframeDepthError)){
      depthErrorDF<-  dataframeDepthError %>% select(date,depthUpperError, depthLowerError)
      depthErrorDF$date <- as.POSIXct(depthErrorDF$date,format="%Y-%m-%d %H:%M:%S",tz="CET") 
      depthErrorDFMerge<- merge(dataframenew, depthErrorDF, by="date", all.x = TRUE) 
      depthErrorDFMerge<-depthErrorDFMerge[order(depthErrorDFMerge$date),]
      dataframenew<-depthErrorDFMerge
    }
    
    
    
    return(dataframenew)
  }
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
# split.hangouts # function to split 'hangouts' if possible for turtle to reach surface based on trajectory. Note- Hangouts indicate ascent, followed by time spent stationary at depth and then descent
#-------------------------------------------------------------------------------
split.hangouts<- function(dataframe){
  
  if (length(which(dataframe$ph3 == "hangout" & dataframe$depth <10))>0){
    
    dataframe$Group <- NA
    # Find the indices where 'hangout' occurs
    hangout_indices <- which(dataframe$ph3 == "hangout"& dataframe$depth <10)
    
    # Assign group numbers to consecutive occurrences of 'hangout'
    group_num <- 1
    for (i in 1:length(hangout_indices)) {
      dataframe$Group[hangout_indices[i]:nrow(dataframe)] <- group_num
      if (i < length(hangout_indices) && hangout_indices[i + 1] != hangout_indices[i] + 1) {
        group_num <- group_num + 1
      }
    }
    dataframe$Group[!dataframe$ph3 %in% "hangout"] <- NA
    
    # Change 'Group' to NA for groups with more than 1 consecutive occurrences  
    df_filt <- as.data.frame(dataframe %>%
                               group_by(Group) %>%
                               mutate(group_count = sum(ph3 == "hangout")) %>%
                               mutate(Group = ifelse(ph3 == "hangout" & group_count > 1, NA, Group)) %>%
                               select(-group_count))
    
    
    hangout_indices <- which(df_filt$ph3 == "hangout")
    
    # Identify the indices where depth remains the same before 'hangout'
    same_depth_before_hangout <- hangout_indices[df_filt$depth[hangout_indices - 1] == df_filt$depth[hangout_indices]]
    
    # Initialize a new column 'Flag' with all FALSE values
    df_filt$Flag <- FALSE
    # Set TRUE for rows in 'Flag' column where depth remains the same before 'hangout'
    df_filt$Flag[same_depth_before_hangout] <- TRUE
    
    df_filt<-as.data.frame(  df_filt %>%
                               group_by(Group) %>%
                               mutate(Group = ifelse(any(Flag), NA, Group)) %>%
                               ungroup())
    
    t<-which(!is.na(df_filt$Group))
    
    
    if (length(t)>1){
      fill=rep(NA, length(t))
      for (a in 1:length(t)){
        #j2<-dataframe[t,2] 
        #depths& times of peak, n-1, n+1
        depthnm1<--dataframe[t[a]-1,2]
        depthpoint<- -dataframe[t[a],2]
        depthnp1<--dataframe[t[a]+1,2]
        
        timenm1<-dataframe[t[a]-1,1]
        timepoint<-dataframe[t[a],1]
        timenp1<-dataframe[t[a]+1,1]
        
        
        #timediff
        t1<-as.numeric(timepoint-timenm1)*60
        t2<-as.numeric(timenp1-timepoint)*60
        
        #depthdiff
        d1<-depthpoint-depthnm1
        d2<-depthpoint-depthnp1
        
        #calculate speed
        #first speed
        s1<-d1/t1
        #second speed
        s2<-d2/t2
        
        #could turtle cross threshold based on speed before/after peak
        distance_poss1<-s1*150
        distance_poss2<-s2*150
        
        distneeded<- -customDive_threshold-depthpoint
        
        if(distance_poss1>=distneeded || distance_poss2>=distneeded ){
          fill[a] = t[a]
        }
        
      }
      
      fill<- fill[!is.na(fill)]
      difcol2<-c(diff(fill),NA) 
      df2<-data.frame(difcol2, fill)
      if(length(which(df2$difcol2==1))>0){
        dfdrop<-df2[-(which(df2$difcol2 %in% "1")),]
      }
      
      fill2<-dfdrop$fill
    }else{
      fill2=t
    }
    
    
    mx<-max(dataframe$depth)
    #need to loop through output from t below
    if (length(fill2)>0){
      fill2<-fill2-1
      
      for (k in 1:length(dataframe)){  
        
        # newdv = rep(NA, nrow(dataframe))
        rwz = fill2
        de=rep(NA, nrow(dataframe))
        newdv<- .POSIXct(character(nrow(dataframe)))
        
        for (i in 1:length(rwz)){
          t1<- dataframe[fill2[i],1] 
          t2 <- t1+150 
          # t<-as.numeric(t1-t1)
          t<-c(0,150)
          d<-c(dataframe[rwz[i],2], 0)
          xout <- seq(t1,t2,by="2 sec") #was 10 secs but changed becasue duplicate confusion
          xout <- as.numeric(xout-t1)
          pred <- aspline(t, d, xout=xout, n=2)  # prediction
          pt <- which(pred$y >= 1)# KEEP AS 1m (top of triangle)
          pt<-rev(pt)
          td1= xout[pt[1]] 
          pt1d<-pt[1]
          
          date<-c(t1+td1)
          depth<- pred$y[pt1d]
          
          newdv[rwz[i]] = as.POSIXct(date)
          de[rwz[i]] = depth 
          
          #ab.thresh#
          pt2<- which(round(pred$y,digits = 2) >= customDive_threshold)
          pt2<-rev(pt2)
          td1.1= xout[pt2[1]] 
          pt2d<-pt2[1]
          date2<-c(t1+td1.1)
          depth2<- pred$y[pt2d]
          
          
          newdv[rwz[i]+1] = as.POSIXct(date2)
          de[rwz[i]+1] = depth2
          
          ###########
          ##descent again, make sure it uses rwz[i], NOT J+1
          tda<- date
          tdb <- dataframe[rwz[i]+1,1] 
          ta<-0 #as.numeric(tdb-tda) #   difftime(tdb,tda, unit="secs"))
          ta<-c(ta,150)
          da<-c(dataframe[rwz[i]+1,2], depth)
          xout2 <- seq(tda, tdb,by="2 sec") #was 10 secs but changed becasue duplicate confusion
          xout2 <- as.numeric(xout2-tda)
          pred2 <- aspline(ta, da, xout=xout2, n=2)  # prediction
          pta <- which(round(pred2$y, digits=2) >= customDive_threshold)# get depths below dive threshold
          pta<-rev(pta)
          td1a= xout[pta[1]] 
          pt1da<-pta[1]
          
          date3<-c(tdb-td1a)
          depth3<- pred2$y[pt1da]
          newdv[rwz[i]+2] = as.POSIXct(date3)
          de[rwz[i]+2] = depth3
        }
        
        dataframe.1<- cbind(dataframe,de,newdv)
        
        df <- dataframe.1[ -c(1:10) ]
        names(df)[names(df) == "newdv"] <- "date"
        names(df)[names(df) == "de"] <- "depth"
        
        
        #final DF!
        multdiv2 <- merge(dataframe,df, by=c("date", "depth"), all = TRUE)
        multdiv2<- multdiv2[complete.cases(multdiv2[ , 1:2]),]
        multdiv2.2<-na.locf(multdiv2, na.rm = FALSE)
        multdiv2.2<-select(multdiv2.2, -c(Group.x, Group.y))
        
        return(multdiv2.2)
      }
    }
  }else{
    
  }
} 
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
# dive_summary # function to extract dive summaries from individual dives
#-------------------------------------------------------------------------------
dive_summary<-function(dataframe){
  #descent time
  bstart<-which(dataframe$ph3=='bottom')
  bstart<-bstart[1]
  descensionTime<-as.numeric(difftime(dataframe[bstart,1], dataframe[1,1], units="secs" ))
  #descent distance
  descd<- rev(which(dataframe$ph3=='descent'))[1]
  descd2<-descd+1
  desc_d<-abs(dataframe[c(1:descd2),8])
  descensionDistance<-sum(desc_d,na.rm=TRUE)
  
  #maximum depth, upper and lower error
  maximumDepth<-dataframe$depth[which.max(dataframe$depth)]
  maximumDepthUpper<-dataframe$depthUpperError[which.max(dataframe$depth)]
  maximumDepthLower<-dataframe$depthLowerError[which.max(dataframe$depth)]
  
  fluc<- filter(dataframe,ph3=='minidesc'| ph3=='miniasc'| ph3=='hangout')
  
  if (nrow(fluc)>0) {
    
    peakfin<- rev(which(dataframe$ph3=='minidesc' | dataframe$ph3=='miniasc'| dataframe$ph3=='hangout'))[1]
    peakfin2<-peakfin+1
    peakstart<- which(dataframe$ph3=='minidesc' | dataframe$ph3=='miniasc'| dataframe$ph3=='hangout')[1]
    
    peak_d<-abs(dataframe[c(peakstart:peakfin2),8])
    peak_dist<-sum(peak_d)
    
    peakTime<-sum(fluc$tim)
    peakHeight<-fluc$depth[which.min(fluc$depth)] #height of peak
    #peak_bot<-fluc$depth[which.max(fluc$depth)] #lowest part of peak
    
    #bottom phase
    bfin<- rev(which(dataframe$ph3 == 'bottom'))[1]
    bottomTime<-as.numeric(difftime(dataframe[bfin,1], dataframe[bstart,1], units= "secs"))
    bottomTime<- bottomTime-peakTime
    bot2<- filter(dataframe,ph3=='bottom')
    botd<-abs(diff(bot2$depth)) #added abs here
    bottomDistance<-sum(botd)
    
    #count number of peaks
    
    dataframe<-dataframe %>%
      mutate(peak_num = case_when(lag(ph3) == "miniasc" & ph3 =="minidesc" ~ '1',
                                  lag(ph3) == "hangout" & ph3 =="minidesc" ~ '1',
                                  lag(ph3) == "minidesc" & ph3 =="miniasc" ~ '1',
                                  TRUE ~ '0'))
    
    dataframe$peak_num<-as.numeric(dataframe$peak_num)
    
    numberOfPeaks<-sum(dataframe$peak_num)
    
    last<-tail(fluc, n=1)
    last[1,1]
    last1<-which(dataframe[,1]== last[1,1])
    last2<-last1+1
    depthafter<-dataframe[last2,2]
    
    #prop of max depth depth after peak is at
    proportionMaxDepthAfterPeak<- depthafter/maximumDepth
    peakSD<- sd(fluc$depth)
    
    
    
  }else {
    peakTime<-NA
    peakHeight<-NA
    # peak_bot<-NA
    numberOfPeaks<-0
    #bottom phase
    bfin<- rev(which(dataframe$ph3 == 'bottom'))[1]
    bottomTime<-as.numeric(difftime(dataframe[bfin,1], dataframe[bstart,1], units= "secs"))
    bot2<- filter(dataframe,ph3=='bottom')
    botd<-abs(diff(bot2$depth))
    bottomDistance<-sum(botd)
    proportionMaxDepthAfterPeak<- NA
    peakSD<- NA
  }
  
  #ascent time
  ascfin<-rev(which(dataframe$ph3 == 'ascent'))[1]
  ascensionTime<-as.numeric(difftime(dataframe[ascfin,1], dataframe[bfin,1], units= "secs"))
  ascent<-dataframe %>% filter(ph3== "ascent")
  ascensionDistance<-sum(abs(ascent$diff),na.rm=TRUE)
  #change point
  a<- filter(dataframe,ph3=='ascent')
  if (nrow(a)>2) {
    asc_cp = cpt.mean((a$spd*100), method="PELT") #mean changepoints using PELT
    numberAscentionChangepoints<-ncpts(asc_cp)
  }else {
    numberAscentionChangepoints<-0
  }
  #add in depth of changepoints
  
  if (numberAscentionChangepoints > 0){
    points<-cpts(asc_cp)
    depth_acp<-a[points,2]
    
    depthAscentionChangepoint1<-depth_acp[1]
    depthAscentionChangepoint2<-depth_acp[2]
    secondAscentionChangepointeighty<-as.integer(depthAscentionChangepoint2> depthAscentionChangepoint1*0.8)
    
  }else {
    depthAscentionChangepoint1<-NA
    depthAscentionChangepoint2<-NA
    secondAscentionChangepointeighty<-NA
  }
  #descent change points
  w<-which(dataframe$ph3 == "descent") 
  if (length(w)>1) {
    first_bot<-w[1]
    desc_filt<-dataframe[2:first_bot,]
    desc_cp = cpt.mean(desc_filt$depth, method="PELT") #mean changepoints using PELT
    numberDescensionChangepoints<-ncpts(desc_cp)
  }else {
    numberDescensionChangepoints<-0
  }
  
  ##depth of desc change points##
  if (numberDescensionChangepoints > 0){
    points2<-cpts(desc_cp)
    depth_dcp<-a[points2,2]
  }else {
    depth_dcp<-NA
  }
  
  diveStartTime<-dataframe[1,1]
  
  #total dive time
  divefin<- rev(dataframe[,1])
  diveEndTime<-divefin[1]
  diveTime<-as.numeric(diveEndTime-diveStartTime)*60
  
 
  nr<- nrow(dataframe)
  maxround<-round(maximumDepth, digits=1) #can get rid of for entire dive cp
  
  if (nr>2 & maxround>customDive_threshold){
    nodesc<- dataframe[dataframe$ph3 != "descent", ]  # #can get rid of for entire dive cp
    
    tot_cp = cpt.mean((nodesc$spd*100), method="PELT") #mean changepoints using PELT
    totalChangepoints<-ncpts(tot_cp)
  }else{
    totalChangepoints=0
  }
  #flag platue in ascent
  plat<-which(a$direction == "no change")
  if (length(plat) > 0 ){
    flatAscentionChangepoint<-"1"
  } else {
    flatAscentionChangepoint<-"0"
  }
  
  #if down again in ascent phase
  down1<-which(a$direction == "positive")
  #if decrease is larger than X meters then dont
  down2<-which(a[down1,8]>2) #change the 2 here for threshold values
  
  if (length(down2) > 0 ){
    descentAfterStatAscent<-length(down2)
  } else {
    descentAfterStatAscent<-"0"
  }
  
  maxDepthUnderTenM<-as.integer(maximumDepth>= 10)
  
  descent<-dataframe %>% filter(ph3== "descent")
  
  botsd<-dataframe%>% filter(!ph3== "descent" & !ph3== "ascent")#anything not asc or desc
  
  bottom<-dataframe %>% filter(ph3== "bottom")
  
  descentSD<-sd(descent$depth)
  restSD<-sd(botsd$depth) #anything not asc or desc
  ascentSD<-sd(ascent$depth)
  bottomSD<- sd(bottom$depth)
  

   if (nrow(a)>1){
     stationaryAscent<-a[1,2]/maximumDepth*100} else{
       stationaryAscent<-NA
     }
  
  #how much of max depth is first ascent?
  #a1/maximumDepth*100
  
  #put all in dataframe
  sum_df<- data.frame(diveStartTime, bottomTime, maximumDepth, bottomDistance, diveTime, totalChangepoints, flatAscentionChangepoint, maxDepthUnderTenM, stationaryAscent,diveEndTime, maximumDepthUpper, maximumDepthLower,flatAscentionChangepoint)
  
  return(sum_df)
  
}
#-------------------------------------------------------------------------------

#-------------------------------------------------------------------------------
# surf.time # function to calculate surface period following a dive
#-------------------------------------------------------------------------------
surf.time<-function(dataframe){
  tim = rep(NA,nrow(dataframe))
  for(i in 2:nrow(dataframe)){
    a = dataframe$diveStartTime[i]
    b = dataframe$diveEndTime[i - 1]
    c = difftime(a,b, unit="secs")
    tim[i] = c
  }
  tim2<-tim[-1]
  tim3<-append(tim2,NA)
  
  dataframe2<-cbind(dataframe,tim3)
  return(dataframe2)
}
#-------------------------------------------------------------------------------

#--------------------------------------------------------------------------------
# getSST     Generate SST product
#--------------------------------------------------------------------------------
getSST <- function(data){
    # This function fixed several problems found on the initial test.
    # 1) I found high temperature values for some points. This is mainly because I initially consider
    #    all dives and postdives. I have sorted this out by:
    #    a) filtering dives >10 minutes long (ie. at least 2 registers per dive).
    #    b) filtering out dives <5 m deep (use lower error estimate). shallow dives could be affected)
    # 2) There were low temperature values for two reasons:
    #    a) Some postdives present without depth data. I filtered those out
    #    b) First register of postdive very similar to previous underwater register. I selected the second register per postdive. 
    
    
    data$surf_int<- NA
    
    j<-2 #j is a counter
    data$surf_int[1] <- 1 #label the first row as 1 so that it is not NA
    
    #loop through and label first surface after dive
    for (i in 2:nrow(data)){      #starts at 2
      if (is.na(data$diveno[i]) & !is.na(data$diveno[i-1])){
        data$surf_int[i] <- j
        j<-j+1
      } 
      print(nrow(data)-i)
    }
    
    data
    
    #nalocf for all surface intervals
    data$surf_int<-na.locf(data$surf_int)
    
    # make sure only surface phases numbered
    data<-data %>%
      mutate(surf_intID = case_when(!is.na(diveno) ~ NA,
                                    TRUE ~ surf_int))
    
    ## First, select dives with more than 10 minutes of duration.
    
    dive10<-dive_summaries %>%
      filter(diveTime>600 & maximumDepth> 5)
    
    
    ## Indetify second time stamp of a postdive
    sst <- data %>%
      group_by(surf_intID) %>%
      arrange(date) %>%
      slice(2) %>%  # take the second register from the postdive
      ungroup
    
    
    
    sst <- filter(sst, surf_intID > 3,  # remove first 3 dives
                  surf_intID %in% dive10$diveID,
                  temperatureQC1 == 1,  # select temperature data within range
                  !is.na(depth.x)) # select data with depth information
    return(sst)
  }
#--------------------------------------------------------------------------------

#--------------------------------------------------------------------------------
# aboveSST     Temperature above SST test
#--------------------------------------------------------------------------------
aboveSST <- function(temp, temp.er, sst, temp.thr = 4){
  # In order to be more consevative, we use the lower band of the temperature data (temperature - temperature error)
  
  tdif <- (temp - temp.er) - sst
  ifelse(tdif >= temp.thr, 4, 1)  # 4: bad data; 1: good data
}
#--------------------------------------------------------------------------------

#-------------------------------------------------------------------------------------------
# depth_error.R     Function to calculate depth error from Time-Series data on SPLASH tags
#-------------------------------------------------------------------------------------------
depth_error <- function(depth, drange, percent=0.01, res=0.5){
  # Arguments:
  # depth           Depth reading (meters, positive value)
  # drange          Resolution of the reading
  # percent         Percentage of the reading
  # res             Sensor resolution
  #
  # Value:
  # Upper and lower depth error (in meters, positive value)
  #
  # Information about the sensor:
  # range: -40 to +1000m
  # resolution: 0.5 m
  # accuracy: +-1% of the reading. Also: 1% of the reading +/-2 depth sensor resolutions
  #
  # Decription:
  # This function only applies for Time-Series data from Wildlife Computers. 
  # Dynamic range of the dive readings during the summary period determine
  # the Time-Series Data resolution (Kevin Lay, Wildlife Computers).
  #
  # Usage:
  # depth <- 60
  # drange <- 6.25
  # e <- depth_error(depth=depth, drange)
  
  # Calculate upper and lower resolution bands
  upper.band <- depth + drange
  lower.band <- depth - drange
  
  # Calculate sensor accuracy for upper and lower bands
  upper.accuracy <- upper.band * percent + 2 * res
  lower.accuracy <- lower.band * percent + 2 * res
  
  # Calculate total depth error (resolution + accuracy)
  upper.error <- upper.band + upper.accuracy
  lower.error <- lower.band - lower.accuracy
  # if(lower.error < 0) lower.error <- 0
  if (any(lower.error < 0)) lower.error[lower.error < 0] <- 0
  
  return(data.frame(upper.error=upper.error, lower.error=lower.error))
}
#-------------------------------------------------------------------------------------------

#-------------------------------------------------------------------------------------------
# temp_error     Function to calculate depth error from Time-Series data on SPLASH tags
#-------------------------------------------------------------------------------------------
temp_error <- function(trange, accuracy = 0.1){
  # Arguments:
  # trange          Resolution of the reading
  # percent         Accuracy of the sensor
  #
  # Value:
  # Temperature error (in degrees)
  #
  # Information about the sensor:
  # range: -40 to 60 degrees celsius
  # resolution: 0.05 degrees
  # accuracy: +- 0.1 degrees
  #
  # Decription:
  # This function only applies for Time-Series data from Wildlife Computers. 
  # Dynamic range of the readings during the summary period determine
  # the Time-Series Data resolution (Kevin Lay, Wildlife Computers).
  #
  # Usage:
  # trange <- 0.85
  # e <- temp_error(trange)
  
  # Calculate total depth error (resolution + accuracy)
  e <- trange + accuracy
  return(e)
}
#-------------------------------------------------------------------------------------------

#--------------------------------------------------------------------------------
# trange_test     QC test using global temperature range
#--------------------------------------------------------------------------------
trange_test <- function(temp, temp.error=0, tmin=10, tmax=40){
  # Arguments
  # t         temperature
  # terror    temperature error. Default is 0 (no error)
  # tmin      minimum temperature range
  # tmax      maximum temperature range
  #
  # Values
  # QC flags: 0, 1, 2, 3, 4, 5
  # Returns NA when temperature data is not available
  #
  # Note
  # temperature range (tmin and tmax) have been calculated for Western Mediterranean...
  # Check what trange variable from Wildlife Computers means
  #
  # Refs:
  # - Argo regional values for Mediterranean Sea (10-40): http://www.argodatamgt.org/content/download/341/2650/file/argo-quality-control-manual-V2.7.pdf
  # - https://www.ukargo.net/data/quality_control/
  #
  # Usage
  # temp <- 18.8
  # temp.error <- 0.95
  # trange_test(temp, temp.error)
  ifelse(temp + temp.error >= tmin & temp - temp.error <= tmax, 1, 4)  # 1: good data; 4: bad data
}
#--------------------------------------------------------------------------------

